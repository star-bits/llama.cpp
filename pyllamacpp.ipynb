{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ace19e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base: /opt/homebrew/Caskroom/miniconda/base/envs/xcda\n",
      "prfx: /opt/homebrew/Caskroom/miniconda/base/envs/xcda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if hasattr(sys, 'base_prefix'):\n",
    "    print(f\"base: {sys.base_prefix}\")\n",
    "\n",
    "if hasattr(sys, 'real_prefix'):\n",
    "    print(f\"real: {sys.real_prefix}\")\n",
    "\n",
    "if hasattr(sys, 'prefix'):\n",
    "    print(f\"prfx: {sys.prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19708339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyllamacpp in /opt/homebrew/Caskroom/miniconda/base/envs/xcda/lib/python3.8/site-packages (1.0.6)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyllamacpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone --recursive https://github.com/nomic-ai/pyllamacpp && cd pyllamacpp\n",
    "# pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec260b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time, 100 years ago in fact, a man named George Washington was born. He grew up to become one of the most influential figures in American history: he led the Continental Army during the American Revolution and served as our nation's first president.\n",
      "As you\n"
     ]
    }
   ],
   "source": [
    "from pyllamacpp.model import Model\n",
    "\n",
    "def new_text_callback(text: str):\n",
    "    print(text, end=\"\", flush=True)\n",
    "\n",
    "model = Model(ggml_model='./models/gpt4all-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin', n_ctx=512)\n",
    "# model.generate(\"Once upon a time, \", n_predict=55, new_text_callback=new_text_callback, n_threads=8)\n",
    "\n",
    "generated_text = model.generate(\"Once upon a time, \", n_predict=55)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9087b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ff6bfcaecee1ee58efd5056b36e79a4e8f4f988a95af2d0be67cac6c4657fe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
